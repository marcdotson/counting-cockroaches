---
title: "Case Study (McKenna)"
author: "McKenna Weech, Hannah Thompson"
date: "3/10/2020"
output: github_document
---

Multi-level regression and post-stratification helps to infer treatment size for a whole population from a non-representative sample. Using population knowledge sample are classified into cells based off of chosen classification variables. Hierarchical Bayesian models are used to infer(?) treatment within cells and population knowledge is used to weight each cell according to their prevalence within the total population. Multilevel regression and poststratification (Gelman & Little, 1997) proceeds by fitting a hierarchical regression model to survey data, and then using the population size of each poststratification cell to construct weighted survey estimates. The accuracy of poststratification within MRP can be dependent on whehter the matrix that is used in poststratification is an accurate representation of the target population. This combination of MRP and postsrtatification has been seen as an effective method when adjusting a sample to be more representative of a population for specific variables.

## Data 

Categorical classification variables are chosen and cell are assigned baised off of category classification. For example, if one variable is gender consisting of two categories (male and other) and one variable is age consisting of two categories (0-50 and 50-100) then there would be four cells: male 0-50, male 50-100, other 0-50, and other 50-100. 

In this case study there are five classification variables choosen: age, income, ethnicity, gender, and state. Each variable is transformed into categorical variables with age having seven categories, income having three, ethnicity having three, gender having two, and state have 50 making the total number of cells 6,300  (7 x 3 x 3 x 2 x 50 = 6300). 

Data is generated using a function from...(find reference).

## Model 

```{r message = FALSE, echo = FALSE}
library(tidyverse) #Load packages
library(rstan)
library(rstanarm)
library(ggplot2)
library(bayesplot)
theme_set(bayesplot::theme_default())
library(dplyr)
library(tidyr)
library(tidybayes)
library(here)

options(mc.cores = parallel::detectCores()) # Set Stan to use all available cores.
rstan_options(auto_write = TRUE)            # Don't recompile Stan code that hasn't changed.

# Data generating function for reference. 
simulate_mrp_data <- function(n) {
  J <- c(2, 3, 7, 3, 50) # male or not, eth, age, income level, state
  poststrat <- as.data.frame(array(NA, c(prod(J), length(J)+1))) # Columns of post-strat matrix, plus one for size
  colnames(poststrat) <- c("male", "eth", "age","income", "state",'N')
  count <- 0
  for (i1 in 1:J[1]){
    for (i2 in 1:J[2]){
      for (i3 in 1:J[3]){
        for (i4 in 1:J[4]){
          for (i5 in 1:J[5]){
              count <- count + 1
              # Fill them in so we know what category we are referring to
              poststrat[count, 1:5] <- c(i1-1, i2, i3, i4, i5)
          }
        }
      }
    }
  }
  # Proportion in each sample in the population
  p_male <- c(0.52, 0.48)
  p_eth <- c(0.5, 0.2, 0.3)
  p_age <- c(0.2,.1,0.2,0.2, 0.10, 0.1, 0.1)
  p_income<-c(.50,.35,.15)
  p_state_tmp<-runif(50,10,20)
  p_state<-p_state_tmp/sum(p_state_tmp)
  poststrat$N<-0
  for (j in 1:prod(J)){
    poststrat$N[j] <- round(250e6 * p_male[poststrat[j,1]+1] * p_eth[poststrat[j,2]] *
      p_age[poststrat[j,3]]*p_income[poststrat[j,4]]*p_state[poststrat[j,5]]) 
    
#Adjust the N to be the number observed in each category in each group
  }

# Now let's adjust for the probability of response
  
  p_response_baseline <- 0.01
  p_response_male <- c(2, 0.8) / 2.8
  p_response_eth <- c(1, 1.2, 2.5) / 4.7
  p_response_age <- c(1, 0.4, 1, 1.5,  3, 5, 7) / 18.9
  p_response_inc <- c(1, 0.9, 0.8) / 2.7
  p_response_state <- rbeta(50, 1, 1)
  p_response_state <- p_response_state / sum(p_response_state)
  p_response <- rep(NA, prod(J))
  for (j in 1:prod(J)) {
    p_response[j] <-
      p_response_baseline * p_response_male[poststrat[j, 1] + 1] *
      p_response_eth[poststrat[j, 2]] * p_response_age[poststrat[j, 3]] *
      p_response_inc[poststrat[j, 4]] * p_response_state[poststrat[j, 5]]
  }
  people <- sample(prod(J), n, replace = TRUE, prob = poststrat$N * p_response)

  ## For respondent i, people[i] is that person's poststrat cell,
  ## some number between 1 and 32
  n_cell <- rep(NA, prod(J))
  for (j in 1:prod(J)) {
    n_cell[j] <- sum(people == j)
  }

  coef_male <- c(0,-0.3)
  coef_eth <- c(0, 0.6, 0.9)
  coef_age <- c(0,-0.2,-0.3, 0.4, 0.5, 0.7, 0.8, 0.9)
  coef_income <- c(0,-0.2, 0.6)
  coef_state <- c(0, round(rnorm(49, 0, 1), 1))
  coef_age_male <- t(cbind(c(0, .1, .23, .3, .43, .5, .6),
                           c(0, -.1, -.23, -.5, -.43, -.5, -.6)))
  true_popn <- data.frame(poststrat[, 1:5], service_failure = rep(NA, prod(J)))
  for (j in 1:prod(J)) {
    true_popn$satisfaction[j] <- plogis(
      coef_male[poststrat[j, 1] + 1] +
        coef_eth[poststrat[j, 2]] + coef_age[poststrat[j, 3]] +
        coef_income[poststrat[j, 4]] + coef_state[poststrat[j, 5]] +
        coef_age_male[poststrat[j, 1] + 1, poststrat[j, 3]]
      )
  }

#male or not, eth, age, income level, state, city
  y <- rbinom(n, 1, true_popn$satisfaction[people])
  male <- poststrat[people, 1]
  eth <- poststrat[people, 2]
  age <- poststrat[people, 3]
  income <- poststrat[people, 4]
  state <- poststrat[people, 5]

  sample <- data.frame(service_failure = y,
                       male, age, eth, income, state,
                       id = 1:length(people))

  #Make all numeric:
  for (i in 1:ncol(poststrat)) {
    poststrat[, i] <- as.numeric(poststrat[, i])
  }
  for (i in 1:ncol(true_popn)) {
    true_popn[, i] <- as.numeric(true_popn[, i])
  }
  for (i in 1:ncol(sample)) {
    sample[, i] <- as.numeric(sample[, i])
  }
  list(
    sample = sample,
    poststrat = poststrat,
    true_popn = true_popn
  )
}

# Importing the data. 
sample <- read_csv(here::here("code", "mrp", "data", "sample.csv"))
proststrat <- read_csv(here::here("code", "mrp", "data", "poststrat.csv"))
true_popn <- read_csv(here::here("code", "mrp", "data", "true_popn.csv"))
```

This case study will use generated data. The data is broken up into three data tables: sample, post-stratification, and population. The post-stratification table shows the population density of each cell and is used to weight the outcome results from the sample. Because the data is generated we also have a generated population that we can use to check the accuracy of the model. 

First we will build a model to predict the our outcome for each cell. Then we will use the post-stratification table to correctly weight each cell to predict outcome for the whole population. 

We will use Bayesian hierarchical modeling to take advantage of partial pooling to account for empty cells. 

### McKenna's logit model

```{r}
predictors <- sample %>% 
  select(male, age, eth, income, state)

data_list <- list(
  D = 5,                                              # Number of variables. 
  N = 1200,                                           # Number of observations.
  L = 5,                                              # Number of groups. 
  y = sample$service_failure,                         # Outcome variables. 
  ll = sample(5, 1200, replace = TRUE),               # Group assignment. 
  x = predictors                                      # Matrix of predictors. 
)
```

```{r, eval = FALSE}
fit <- stan(
  file = here::here("Code", "mrp", "logit_hier.stan"),
  data = data_list,
  seed = 42 
)
```

#### Downes logit model 

```{r}
# Observations. 
downes_list <- list(
  outcome = sample$service_failure,
  male = sample$male + 1,
  age = sample$age, 
  eth = sample$eth, 
  income = sample$income,
  state = sample$state,
  n = length(sample$service_failure), 
  n_male = max(sample$male) + 1,
  n_age = max(sample$age),
  n_eth = max(sample$eth),
  n_income = max(sample$income),
  n_state = max(sample$state)
)
```

```{r, eval = FALSE}
fit <- stan(
  file = here::here("Code", "mrp", "downes_copy.stan"),
  data = downes_list,
  seed = 42 
)
```

#### Stan user guide logit model 

```{r}
stan_data <- list( 
  age = sample$age, 
  eth = sample$eth, 
  income = sample$income, 
  male = sample$male, 
  state = sample$state, 
  Y = sample$service_failure, 
  N = length(sample$service_failure)
)
```

```{r, eval = FALSE}
fit <- stan(
  file = here::here("Code", "mrp", "stan_mrp.stan"),
  data = stan_data,
  seed = 42 
)
```

## Post-Stratification 

Post-stratification consists of taking the sum of the estimates of the model for each cell times the number of people in each cell divided by the total number of people. Using poststratificationcan immprove accracy of the estimates based on the information known.

$$\omega=\displaystyle\frac{$$\sum_{j=1}^{J}\beta_{j}*N_{j}$$}{$$\sum_{j=1}^{J}N_{j}$$}$$
Post-stratification can be performed in stan using the generated quantities block.

```{r, eval = FALSE}
generated quantities {
  real expect_pos = 0;
  int total = 0;
  for (b in 1:7)
    for (c in 1:3)
      for (d in 1:3)
        for (f in 1:2)
          for (g in 1:50) {
        total += P[b, c, d, f, g];
        expect_pos
          += P[b, c, d, f, g]
             * inv_logit(b0 + a_age[b] + a_eth[c] + a_income[d] + a_male[f] + a_state[g]);
      }
  real<lower = 0, upper = 1> phi = expect_pos / total;
}           
```

## Compare to Population 

Because we are using simulated data we can see how our poststratified predictions compare to the true population.
